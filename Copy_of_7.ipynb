{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noviceswing/DEEPLEARING-pytorch/blob/main/Copy_of_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bp7o0FZotw1D"
      },
      "outputs": [],
      "source": [
        "# 基于注意力机制的机器翻译\n",
        "# 导入需要的库\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import unicodedata\n",
        "import re\n",
        "import os\n",
        "import io\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xShctwV1dFby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPIGaWXXtw1E",
        "outputId": "a66aa40e-ad00-4543-ba11-0392a27a93f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.keras/datasets\n"
          ]
        }
      ],
      "source": [
        "# 用代码下载anki数据集\n",
        "path_to_zip = tf.keras.utils.get_file('spa-eng.zip',\n",
        "                          origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "                                    extract=True)\n",
        "print(os.path.dirname(path_to_zip))\n",
        "path_to_file = os.path.dirname(path_to_zip) + \"/spa-eng/spa.txt\"\n",
        "\n",
        "# 该数据集会存储在keras安装目录的datasets下\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxL0yDSwtw1F",
        "outputId": "335807ae-9e10-4cf5-b3ad-0aedecd71df2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
          ]
        }
      ],
      "source": [
        "# 将 unicode 文件转换为 ascii\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    # 在单词与跟在其后的标点符号之间插入一个空格\n",
        "    # 例如： \"he is a boy.\" => \"he is a boy .\"\n",
        "    # 参考：https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # 除了 (a-z, A-Z, \".\", \"?\", \"!\", \",\")，将所有字符替换为空格\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.rstrip().strip()\n",
        "\n",
        "    # 给句子加上开始和结束标记\n",
        "    # 以便模型知道何时开始和结束预测\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "\n",
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 去除重音符号\n",
        "# 2. 清理句子\n",
        "# 3. 返回这样格式的单词对：[ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "\n",
        "    return zip(*word_pairs)\n",
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5PsnJ3q-535",
        "outputId": "6309cf49-795b-44e2-8502-96d715ff9dfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "metadata": {
        "id": "4d7NETI3_DQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9UXR00Etw1F",
        "outputId": "1c01833f-5b91-449a-db85-82d58395e5c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24000 24000 6000 6000\n"
          ]
        }
      ],
      "source": [
        "# 将文本转换成数字序列\n",
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer\n",
        "\n",
        "# 定义加载数据集\n",
        "def load_dataset(path, num_examples=None):\n",
        "    # 创建清理过的输入输出对\n",
        "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n",
        "\n",
        "# 尝试实验不同大小的数据集\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# 计算目标张量的最大长度 （max_length）\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
        "\n",
        "# 采用 80 - 20 的比例切分训练集和验证集\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# 显示长度\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))\n"
      ],
      "metadata": {
        "id": "OOaIJ_jr_2Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeBJrk_R_567",
        "outputId": "bc789789-1295-416d-f513-0c3d50c6e57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "8 ----> no\n",
            "17 ----> se\n",
            "6077 ----> quedaran\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "28 ----> they\n",
            "100 ----> won\n",
            "12 ----> t\n",
            "120 ----> stay\n",
            "3 ----> .\n",
            "2 ----> <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_F1cXQ8tw1F",
        "outputId": "fe1c834f-e34f-4c60-86b3-1bfb38cb4481"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc4vyvSLtw1G",
        "outputId": "b41f55ca-1997-4364-89f0-203d12d66bf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ]
        }
      ],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# 样本输入\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGElQwhbtw1G",
        "outputId": "e8d1c538-5770-43a6-f68d-3a886ab5504b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ]
        }
      ],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # 隐藏层的形状 == （批大小，隐藏层大小）\n",
        "    # hidden_with_time_axis 的形状 == （批大小，1，隐藏层大小）\n",
        "    # 这样做是为了执行加法以计算分数\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # 分数的形状 == （批大小，最大长度，1）\n",
        "    # 我们在最后一个轴上得到 1， 因为我们把分数应用于 self.V\n",
        "    # 在应用 self.V 之前，张量的形状是（批大小，最大长度，单位）\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # 注意力权重 （attention_weights） 的形状 == （批大小，最大长度，1）\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # 上下文向量 （context_vector） 求和之后的形状 == （批大小，隐藏层大小）\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhVi7Xjjtw1G",
        "outputId": "bf638f7b-ef71-47ee-d3d6-da49bb080613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
          ]
        }
      ],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # 用于注意力\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # 编码器输出 （enc_output） 的形状 == （批大小，最大长度，隐藏层大小）\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x 在通过嵌入层后的形状 == （批大小，1，嵌入维度）\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x 在拼接 （concatenation） 后的形状 == （批大小，1，嵌入维度 + 隐藏层大小）\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # 将合并后的向量传送到 GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # 输出的形状 == （批大小 * 1，隐藏层大小）\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # 输出的形状 == （批大小，vocab）\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights\n",
        "\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltYShh79tw1G"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7HFkjkKtw1H",
        "outputId": "7435f1b2-6b7e-4a87-f767-9efa57155e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 4.6024\n",
            "Epoch 1 Batch 100 Loss 2.2012\n",
            "Epoch 1 Batch 200 Loss 1.8533\n",
            "Epoch 1 Batch 300 Loss 1.7553\n",
            "Epoch 1 Loss 2.0608\n",
            "Time taken for 1 epoch 48.127368688583374 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.6409\n",
            "Epoch 2 Batch 100 Loss 1.6197\n",
            "Epoch 2 Batch 200 Loss 1.4598\n",
            "Epoch 2 Batch 300 Loss 1.3293\n",
            "Epoch 2 Loss 1.4501\n",
            "Time taken for 1 epoch 29.37078833580017 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.1196\n",
            "Epoch 3 Batch 100 Loss 1.0889\n",
            "Epoch 3 Batch 200 Loss 1.1044\n",
            "Epoch 3 Batch 300 Loss 1.0188\n",
            "Epoch 3 Loss 1.0599\n",
            "Time taken for 1 epoch 28.69797706604004 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.8160\n",
            "Epoch 4 Batch 100 Loss 0.7569\n",
            "Epoch 4 Batch 200 Loss 0.5921\n",
            "Epoch 4 Batch 300 Loss 0.7222\n",
            "Epoch 4 Loss 0.7468\n",
            "Time taken for 1 epoch 28.77109408378601 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.5514\n",
            "Epoch 5 Batch 100 Loss 0.5383\n",
            "Epoch 5 Batch 200 Loss 0.4907\n",
            "Epoch 5 Batch 300 Loss 0.5630\n",
            "Epoch 5 Loss 0.5264\n",
            "Time taken for 1 epoch 28.49280858039856 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 开始训练模型\n",
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # 教师强制 - 将目标词作为下一个输入\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # 将编码器输出 （enc_output） 传送至解码器\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # 使用教师强制\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                     batch,\n",
        "                                                     batch_loss.numpy()))\n",
        "  # 每 2 个周期（epoch），保存（检查点）一次模型\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hX_IGlpHtw1H"
      },
      "outputs": [],
      "source": [
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                           maxlen=max_length_inp,\n",
        "                                                           padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        # 存储注意力权重以便后面制图\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # 预测的 ID 被输送回模型\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08GRGJ_ptw1H"
      },
      "outputs": [],
      "source": [
        "# 注意力权重制图函数\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FOk3qg6tw1I",
        "outputId": "fc5891eb-b6a5-4651-bba4-38c8a680347f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it s very cold . <end> \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-7196e6270c60>:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
            "<ipython-input-16-7196e6270c60>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 加载保存的模型\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "# 开始翻译\n",
        "translate(u'hace mucho frio aqui.')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}